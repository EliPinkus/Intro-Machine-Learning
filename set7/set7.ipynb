{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import random as ran\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opening data and cleaning it into usable format\n",
    "with open('in.dta','r') as tsv:\n",
    "    raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "split = []\n",
    "for pt in raw:\n",
    "    split.append(pt[0].split())\n",
    "    \n",
    "in_data = []\n",
    "for pt in split:\n",
    "    in_data.append([np.array([float(pt[0]),float(pt[1])]),float(pt[2])])\n",
    "    \n",
    "with open('out.dta','r') as tsv:\n",
    "    raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "split = []\n",
    "for pt in raw:\n",
    "    split.append(pt[0].split())\n",
    "    \n",
    "out_data = []\n",
    "for pt in split:\n",
    "    out_data.append([np.array([float(pt[0]),float(pt[1])]),float(pt[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining phi's\n",
    "p0 = lambda x1,x2: 1\n",
    "p1 = lambda x1,x2: x1\n",
    "p2 = lambda x1,x2: x2\n",
    "p3 = lambda x1,x2: x1**2\n",
    "p4 = lambda x1,x2: x2**2\n",
    "p5 = lambda x1,x2: x1*x2\n",
    "p6 = lambda x1,x2: np.abs(x1-x2)\n",
    "p7 = lambda x1,x2: np.abs(x1+x2)\n",
    "phis=[p0,p1,p2,p3,p4,p5,p6,p7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans(pt, k):\n",
    "    x = []\n",
    "    for i in range(k+1):\n",
    "        x.append(phis[i](pt[0][0],pt[0][1]))\n",
    "        \n",
    "    return [np.array(x), pt[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_out for the transform with k=3 is 0.42\n",
      "E_val for the transform with k=3 is 0.3\n",
      "\n",
      "E_out for the transform with k=4 is 0.416\n",
      "E_val for the transform with k=4 is 0.5\n",
      "\n",
      "E_out for the transform with k=5 is 0.188\n",
      "E_val for the transform with k=5 is 0.2\n",
      "\n",
      "E_out for the transform with k=6 is 0.084\n",
      "E_val for the transform with k=6 is 0.0\n",
      "\n",
      "E_out for the transform with k=7 is 0.072\n",
      "E_val for the transform with k=7 is 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing k values\n",
    "\n",
    "ks = [3,4,5,6,7]\n",
    "for k in ks:\n",
    "    trans_data = []\n",
    "    for pt in in_data:\n",
    "        trans_data.append(trans(pt,k))\n",
    "\n",
    "    train = trans_data[0:25]\n",
    "    val = trans_data[25:]\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for pt in train:\n",
    "        X.append(pt[0])\n",
    "        y.append(pt[1])\n",
    "\n",
    "    # standard linear regression\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    xp = np.linalg.pinv(X)\n",
    "    w = xp @ y\n",
    "\n",
    "    e_val = 0\n",
    "    for pt in val:\n",
    "        if not np.sign(w.dot(pt[0])) == np.sign(pt[1]):\n",
    "            e_val += 1\n",
    "            \n",
    "    e_out = 0\n",
    "    for pt in out_data:\n",
    "        tpt = trans(pt,k)\n",
    "        if not np.sign(w.dot(tpt[0])) == np.sign(pt[1]):\n",
    "            e_out += 1\n",
    "\n",
    "    print(\"E_out for the transform with k=\" + str(k) + \" is \" + str(float(e_out)/float(len(out_data))))\n",
    "\n",
    "    print (\"E_val for the transform with k=\" + str(k) + \" is \" + str(e_val / float(len(val)))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02336115, -0.09453057,  0.16020727,  0.43355141])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_out for the transform with k=3 is 0.396\n",
      "E_val for the transform with k=3 is 0.28\n",
      "\n",
      "E_out for the transform with k=4 is 0.388\n",
      "E_val for the transform with k=4 is 0.36\n",
      "\n",
      "E_out for the transform with k=5 is 0.284\n",
      "E_val for the transform with k=5 is 0.2\n",
      "\n",
      "E_out for the transform with k=6 is 0.192\n",
      "E_val for the transform with k=6 is 0.08\n",
      "\n",
      "E_out for the transform with k=7 is 0.196\n",
      "E_val for the transform with k=7 is 0.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ks = [3,4,5,6,7]\n",
    "for k in ks:\n",
    "    trans_data = []\n",
    "    for pt in in_data:\n",
    "        trans_data.append(trans(pt,k))\n",
    "\n",
    "    val = trans_data[0:25]\n",
    "    train = trans_data[25:]\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for pt in train:\n",
    "        X.append(pt[0])\n",
    "        y.append(pt[1])\n",
    "\n",
    "    # standard linear regression\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    xp = np.linalg.pinv(X)\n",
    "    w = xp @ y\n",
    "\n",
    "    e_val = 0\n",
    "    for pt in val:\n",
    "        if not np.sign(w.dot(pt[0])) == np.sign(pt[1]):\n",
    "            e_val += 1\n",
    "            \n",
    "    e_out = 0\n",
    "    for pt in out_data:\n",
    "        tpt = trans(pt,k)\n",
    "        if not np.sign(w.dot(tpt[0])) == np.sign(pt[1]):\n",
    "            e_out += 1\n",
    "\n",
    "    print(\"E_out for the transform with k=\" + str(k) + \" is \" + str(float(e_out)/float(len(out_data))))\n",
    "\n",
    "    print (\"E_val for the transform with k=\" + str(k) + \" is \" + str(e_val / float(len(val)))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLine():\n",
    "    (x1, y1) = (ran.uniform(-1,1), ran.uniform(-1,1))\n",
    "    (x2, y2) = (ran.uniform(-1,1), ran.uniform(-1,1))\n",
    "    line = lambda x:(y2-y1)/(x2-x1)*(x-x1)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelPts(N, line):\n",
    "    pts = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        (x1,x2) = ran.uniform(-1,1), ran.uniform(-1,1)\n",
    "        \n",
    "        pts.append([np.array([1,x1,x2,]),np.sign(x2-line(x1))])\n",
    "    \n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PLA function\n",
    "\n",
    "def runPerceptron(data, line):\n",
    "    w = np.array([0.0,0.0,0.0])\n",
    "    mis_pts = []\n",
    "    for pt in data:\n",
    "        mis_pts.append(pt)\n",
    "\n",
    "    iters = 0\n",
    "    while len(mis_pts) is not 0:\n",
    "        # choose randoim missclasified point and update\n",
    "        pt = ran.choice(mis_pts)\n",
    "\n",
    "        w = w + np.multiply(pt[1],pt[0])\n",
    "\n",
    "\n",
    "        # recheck for misclassified points\n",
    "        mis_pts = []\n",
    "\n",
    "        for pt in data:\n",
    "            if np.sign(w.dot(pt[0])) != pt[1]:\n",
    "                mis_pts.append(pt)\n",
    "        iters += 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare PLA with SVM for N=10\n",
    "svm_wins = 0\n",
    "count = 0\n",
    "while count <1000:\n",
    "    \n",
    "    line = getLine()\n",
    "    data = labelPts(10,line)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for pt in data:\n",
    "        X.append(pt[0])\n",
    "        y.append(pt[1])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    if not(not 1.0 in y or not -1.0 in y):\n",
    "        count += 1\n",
    "        \n",
    "        w = runPerceptron(data, line)\n",
    "        s = svm.SVC(kernel='linear', C=100000000)\n",
    "        s.fit(X,y)\n",
    "        \n",
    "        test_data = labelPts(1000, line)\n",
    "    \n",
    "        E_svm = 0\n",
    "        E_pla = 0\n",
    "        for pt in test_data:\n",
    "            if np.sign(w.dot(pt[0])) != pt[1]:\n",
    "                E_pla += 1\n",
    "\n",
    "            SVM_guess = s.predict([pt[0]])\n",
    "            if float(SVM_guess[0]) != np.sign(pt[1]):\n",
    "                E_svm += 1\n",
    "\n",
    "        if E_svm < E_pla:\n",
    "            svm_wins += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM is better 625 out of 1000 runs\n"
     ]
    }
   ],
   "source": [
    "print (\"SVM is better \" + str(svm_wins) + \" out of 1000 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare PLA with SVM for N=100\n",
    "svm_wins = 0\n",
    "count = 0\n",
    "svs = []\n",
    "while count <1000:\n",
    "    line = getLine()\n",
    "    data = labelPts(100,line)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for pt in data:\n",
    "        X.append(pt[0])\n",
    "        y.append(pt[1])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    if not (not 1.0 in y or not -1.0 in y):\n",
    "        count += 1\n",
    "        \n",
    "        w = runPerceptron(data, line)\n",
    "        s = svm.SVC(kernel='linear', C=100000000)\n",
    "        s.fit(X,y)\n",
    "        svs.append(len(s.support_vectors_))\n",
    "        \n",
    "        test_data = labelPts(1000, line)\n",
    "    \n",
    "        E_svm = 0\n",
    "        E_pla = 0\n",
    "        for pt in test_data:\n",
    "            if np.sign(w.dot(pt[0])) != pt[1]:\n",
    "                E_pla += 1\n",
    "\n",
    "            SVM_guess = s.predict([pt[0]])\n",
    "            if float(SVM_guess[0]) != np.sign(pt[1]):\n",
    "                E_svm += 1\n",
    "\n",
    "        if E_svm < E_pla:\n",
    "            svm_wins += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM is better 597 out of 1000 runs\n"
     ]
    }
   ],
   "source": [
    "print (\"SVM is better \" + str(svm_wins) + \" out of 1000 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are an average of 2.998 support vectors\n"
     ]
    }
   ],
   "source": [
    "print (\"There are an average of \" + str(np.mean(svs)) + \" support vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
