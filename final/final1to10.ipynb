{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import random as ran\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features.train','r') as tsv:\n",
    "    raw = [line.strip().split('\\t') for line in tsv]\n",
    "    \n",
    "split = []\n",
    "for pt in raw:\n",
    "    split.append(pt[0].split())\n",
    "    \n",
    "train = []\n",
    "for pt in split:\n",
    "    train.append([np.array([float(pt[1]),float(pt[2])]),int(float(pt[0]))])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regularized linear regression\n",
    "def reg_reg(X,y, lamb):\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    I = np.matrix(np.identity(len(X[0])))\n",
    "    lam = lamb\n",
    "    L = X.transpose()*X + lam * I\n",
    "    w_reg = np.array(np.linalg.inv(L)*X.transpose()*y.transpose())\n",
    "    w_reg = w_reg.transpose()\n",
    "    return w_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare data for k versus all:\n",
    "e_ins = []\n",
    "for k in [5,6,7,8,9]:\n",
    "    with open('features.train','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "\n",
    "    train = []\n",
    "    for pt in split:\n",
    "        train.append([np.array([1,float(pt[1]),float(pt[2])]),float(pt[0])])\n",
    "    for pt in train:\n",
    "        if pt[1] == k:\n",
    "            pt[1] = 1.0\n",
    "        else:\n",
    "            pt[1] = -1.0\n",
    "\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for pt in train:\n",
    "        X_train.append(pt[0])\n",
    "        y_train.append(pt[1])\n",
    "    \n",
    "    w = reg_reg(X_train, y_train,1)\n",
    "    \n",
    "    errors = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        if not np.sign(w.dot(X_train[i])) == np.sign(y_train[i]):\n",
    "            errors += 1\n",
    "    e_ins.append((errors/len(X_train),k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07433822520916199, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(e_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data for k versus all:\n",
    "e_ins = []\n",
    "for k in [0,1,2,3,4]:\n",
    "    with open('features.train','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "\n",
    "    train = []\n",
    "    for pt in split:\n",
    "        train.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),float(pt[0])])\n",
    "    for pt in train:\n",
    "        if pt[1] == k:\n",
    "            pt[1] = 1.0\n",
    "        else:\n",
    "            pt[1] = -1.0\n",
    "\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for pt in train:\n",
    "        X_train.append(pt[0])\n",
    "        y_train.append(pt[1])\n",
    "    \n",
    "    w = reg_reg(X_train, y_train,1)\n",
    "    \n",
    "    errors = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        if not np.sign(w.dot(X_train[i])) == np.sign(y_train[i]):\n",
    "            errors += 1\n",
    "    e_ins.append((errors/len(X_train),k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01275545192703333, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(e_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare data for k versus all:\n",
    "trans_e_ins = []\n",
    "trans_e_outs = []\n",
    "for k in [0,1,2,3,4,5,6,7,8,9]:\n",
    "    with open('features.train','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "\n",
    "    train = []\n",
    "    for pt in split:\n",
    "        train.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),float(pt[0])])\n",
    "    for pt in train:\n",
    "        if pt[1] == k:\n",
    "            pt[1] = 1.0\n",
    "        else:\n",
    "            pt[1] = -1.0\n",
    "\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for pt in train:\n",
    "        X_train.append(pt[0])\n",
    "        y_train.append(pt[1])\n",
    "    \n",
    "    w = reg_reg(X_train, y_train,1)\n",
    "    \n",
    "    errors = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        if not np.sign(w.dot(X_train[i])) == np.sign(y_train[i]):\n",
    "            errors += 1\n",
    "    trans_e_ins.append((errors/len(X_train),k))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # format testing data\n",
    "    with open('features.test','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "        \n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "    \n",
    "    errors = 0.0\n",
    "    test = []\n",
    "    for pt in split:\n",
    "        if float(pt[0]) == k:\n",
    "            test.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),1.0])\n",
    "        else:\n",
    "            test.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),-1.0])\n",
    "    for pt in test:\n",
    "        if not np.sign(w.dot(pt[0])) == np.sign(pt[1]):\n",
    "        \n",
    "            errors += 1\n",
    "    trans_e_outs.append((errors/len(test),k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare data for k versus all:\n",
    "e_ins = []\n",
    "e_outs = []\n",
    "for k in [0,1,2,3,4,5,6,7,8,9]:\n",
    "    with open('features.train','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "\n",
    "    train = []\n",
    "    for pt in split:\n",
    "        train.append([np.array([1,float(pt[1]),float(pt[2])]),float(pt[0])])\n",
    "    for pt in train:\n",
    "        if pt[1] == k:\n",
    "            pt[1] = 1.0\n",
    "        else:\n",
    "            pt[1] = -1.0\n",
    "\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for pt in train:\n",
    "        X_train.append(pt[0])\n",
    "        y_train.append(pt[1])\n",
    "    \n",
    "    w = reg_reg(X_train, y_train,1)\n",
    "    \n",
    "    errors = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        if not np.sign(w.dot(X_train[i])) == np.sign(y_train[i]):\n",
    "            errors += 1\n",
    "    e_ins.append((errors/len(X_train),k))\n",
    "    \n",
    "    \n",
    "    # format testing data\n",
    "    with open('features.test','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "        \n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "    \n",
    "    errors = 0.0\n",
    "    test = []\n",
    "    for pt in split:\n",
    "        if float(pt[0]) == k:\n",
    "            test.append([np.array([1,float(pt[1]),float(pt[2])]),1.0])\n",
    "        else:\n",
    "            test.append([np.array([1,float(pt[1]),float(pt[2])]),-1.0])\n",
    "            \n",
    "    for pt in test:\n",
    "        if not np.sign(w.dot(pt[0])) == np.sign(pt[1]):\n",
    "        \n",
    "            errors += 1\n",
    "    e_outs.append((errors/len(test),k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.11559541604384654, 0),\n",
       " (0.0229197807673144, 1),\n",
       " (0.09865470852017937, 2),\n",
       " (0.08271051320378675, 3),\n",
       " (0.09965122072745392, 4),\n",
       " (0.07972097658196313, 5),\n",
       " (0.08470353761833582, 6),\n",
       " (0.07324364723467862, 7),\n",
       " (0.08271051320378675, 8),\n",
       " (0.08819133034379671, 9)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10363726955655207, 0),\n",
       " (0.02192326856003986, 1),\n",
       " (0.09865470852017937, 2),\n",
       " (0.08271051320378675, 3),\n",
       " (0.09965122072745392, 4),\n",
       " (0.07922272047832586, 5),\n",
       " (0.08470353761833582, 6),\n",
       " (0.07324364723467862, 7),\n",
       " (0.08271051320378675, 8),\n",
       " (0.08819133034379671, 9)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_e_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10890138526951036, 0),\n",
       " (0.01522424907420107, 1),\n",
       " (0.10026059525442327, 2),\n",
       " (0.09024825126868742, 3),\n",
       " (0.08942531888629818, 4),\n",
       " (0.07625840076807022, 5),\n",
       " (0.09107118365107666, 6),\n",
       " (0.08846523110684405, 7),\n",
       " (0.07433822520916199, 8),\n",
       " (0.08832807570977919, 9)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.09984912906322864, 0),\n",
       " (0.01275545192703333, 1),\n",
       " (0.10026059525442327, 2),\n",
       " (0.09024825126868742, 3),\n",
       " (0.08942531888629818, 4),\n",
       " (0.07625840076807022, 5),\n",
       " (0.09107118365107666, 6),\n",
       " (0.08846523110684405, 7),\n",
       " (0.07433822520916199, 8),\n",
       " (0.08832807570977919, 9)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_e_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lams=[1,.01]\n",
    "e_ins = []\n",
    "e_outs = []\n",
    "k1,k2=1,5\n",
    "for lam in lams:\n",
    "    # format train data\n",
    "    with open('features.train','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "\n",
    "\n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "\n",
    "    train = []\n",
    "    for pt in split:\n",
    "        if float(pt[0]) == k1:\n",
    "            train.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),1.0])\n",
    "        elif float(pt[0]) == k2:\n",
    "            train.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),-1.0])\n",
    "\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for pt in train:\n",
    "        X.append(pt[0])\n",
    "        y.append(pt[1])\n",
    "        \n",
    "    # format test data\n",
    "    with open('features.test','r') as tsv:\n",
    "        raw = [line.strip().split('\\t') for line in tsv]\n",
    "\n",
    "\n",
    "\n",
    "    split = []\n",
    "    for pt in raw:\n",
    "        split.append(pt[0].split())\n",
    "\n",
    "    test = []\n",
    "    for pt in split:\n",
    "        if float(pt[0]) == k1:\n",
    "            test.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),1.0])\n",
    "        elif float(pt[0]) == k2:\n",
    "            test.append([np.array([1,float(pt[1]),float(pt[2]),float(pt[1])*float(pt[2]),float(pt[1])**2,float(pt[2])**2]),-1.0])\n",
    "\n",
    "\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for pt in test:\n",
    "        X_test.append(pt[0])\n",
    "        y_test.append(pt[1])\n",
    "    \n",
    "    w = reg_reg(X, y,lam)\n",
    "    \n",
    "    results_out = [np.sign(w.dot(X_test[i])) == np.sign(y_test[i]) for i in range(len(X_test))]\n",
    "    results_in = [np.sign(w.dot(X[i])) == np.sign(y[i]) for i in range(len(X))]\n",
    "    \n",
    "    e_ins.append((results_in.count(False)/len(results_in),lam))\n",
    "    e_outs.append((results_out.count(False)/len(results_out),lam))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.005124919923126201, 1), (0.004484304932735426, 0.01)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.025943396226415096, 1), (0.02830188679245283, 0.01)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
